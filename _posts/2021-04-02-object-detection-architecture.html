---
layout: default
title: "Object Detection Architecture"
date: 2021-04-22 09:00:00 +0700
published: 2021-05-21 09:00:00 +0700
comments: true
categories: development
tags: [deeplearning, machinelearning, AI]
---

<p>In Computer Vision, Object Detection is very essential problem. We had a lot of architecture: Dense, CNN, Transformer.... Today, we'll deep dive into it.</p>
<h2>Transformer Based</h2>
<p> Anchor-based approach of Yolo can improve speed, but we need NMS and some post process for noise filer </p>
<p> It's waste time in tuning. So we can use Transformer architecture for end to end training and inference.</p>

<h3>Architecture</h3>
<img src="/assets/images/posts/object-detection-architecture/top.jpg" alt="Detection Transformer">


<p> Output: <br>
    + pred_logits: The classification logits for each query, which predict the probability of each class for the detected objects, including a "no-object" class.<br>
    + pred_boxes: The coordinates of the predicted bounding boxes normalized to the size of the image.<br>
    + aux_outputs: Additional outputs from each transformer decoder layer, used when auxiliary losses are activated. <br>
</p>
<p>
    MLP (Multi-Layer Perceptron): A simple fully connected network used within the DETR model to process features (e.g., to compute bounding box coordinates).<br>
</p>
<p>
QKV:
+ Q: using embedding to represent objects<br>
+ K and V: projected to KV by linear layers. Key for correlations between query and position in image.<br>
V offer info to update status of query in loop of transformer. <br>
</p>
<h3>Metrics/Loss</h3>
<p>
SetCriterion: This class calculates several losses for training the DETR model. It uses:<br>
    + A Hungarian matcher to associate predicted boxes and classes with ground truth boxes and classes.<br>
    + Loss calculations for classification (loss_ce), bounding box regression (loss_bbox), GIoU (loss_giou), and optionally, mask losses (loss_mask, loss_dice) if segmentation masks are being predicted.<br>
    + Cardinality loss (loss_cardinality) which measures the error in the number of predicted objects versus the actual number of objects.<br>
</p>

<h2>CNN</h2>
<img src="/assets/images/posts/object-detection-architecture/ResNet50.png" alt="ResNet BackBone">
<img src="/assets/images/posts/object-detection-architecture/yolov8.png" alt="Yolov8">

<h3>Architecture</h3>
<p>
Using Convol technique with kernel for scaning -> learning feature from images.<br>
In Yolo, we have Anchor-based technique to stable learning. Model classify anchor box and minimize IoU.<br>
+ Bottle-neck block<br>
+ Spatial Pyramid Pooling - Fast<br>
+ Skip connections<br>
+ Concatenation<br>
+ SiLU<br>
+ Batch Normalization<br>
+ Max Pooling layers<br>
+ Assorted hyperparameters<br>
+ IOU thresholds v√† loss functions<br>
+ Attention Mechanism<br>
</p>

<h3>Data Augumentation</h3>
<p>
    Using Mosaic Mixup Augumentation to avoid overfiting and improve accuracy in test.
</p>

<h3>Loss</h3>

<p>
    + Varifocal loss <br>
    + BCE loss <br>
    + BCE loss <br>
    + Bbox loss <br>
    + RotatedBboxLoss<br>
    + KeypointLoss<br>
</p>

<h3>Initial technique</h3>
<p>
Using weight init to set bias conv detect = -1 to almost anchor output will overlapse with groundtruth.<br>
Set bias conv classify = -3 to accuracy from start, is background, only learn positive<br>
</p>

<h2>Mask R-CNN/Faster R-CNN</h2>
<h3>Architecture</h3>

<img src="/assets/images/posts/object-detection-architecture/maskrcnn-big-picture.png" alt="Yolov8">

<p>
    + DETR and Faster R-CNN have the same params. Faster R-CNN better mAP than DETR in small object. But normal object is better.<br>
    + R is Region Proposal Network, -> Classify and regression.<br>
    + Mask is a segmentation to offer RoIPool. We need to fine tune Mask in 1st phase. After that, Object Det fine-tuning<br>
    + Using Feature Pyramid Networks (FPNs).<br>
</p>

<h3>Loss</h3>

<p>
    + Classification Loss: BCE or CE. (multilabel or unilabel)<br>
    + Mask Loss: Binary Cross-Entropy for every pixel.<br>
    + BBox Loss: Smooth L1 Loss (regression loss)<br>
</p>



